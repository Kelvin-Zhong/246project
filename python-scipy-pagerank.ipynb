{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx\n",
    "def pagerank_scipy(G, alpha=0.85, personalization=None,\n",
    "                   max_iter=100, tol=1.0e-6, weight='weight',\n",
    "                   dangling=None):\n",
    "    \"\"\"Return the PageRank of the nodes in the graph.\n",
    "\n",
    "    PageRank computes a ranking of the nodes in the graph G based on\n",
    "    the structure of the incoming links. It was originally designed as\n",
    "    an algorithm to rank web pages.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    G : graph\n",
    "      A NetworkX graph.  Undirected graphs will be converted to a directed\n",
    "      graph with two directed edges for each undirected edge.\n",
    "\n",
    "    alpha : float, optional\n",
    "      Damping parameter for PageRank, default=0.85.\n",
    "\n",
    "    personalization: dict, optional\n",
    "       The \"personalization vector\" consisting of a dictionary with a\n",
    "       key for every graph node and nonzero personalization value for each\n",
    "       node. By default, a uniform distribution is used.\n",
    "\n",
    "    max_iter : integer, optional\n",
    "      Maximum number of iterations in power method eigenvalue solver.\n",
    "\n",
    "    tol : float, optional\n",
    "      Error tolerance used to check convergence in power method solver.\n",
    "\n",
    "    weight : key, optional\n",
    "      Edge data key to use as weight.  If None weights are set to 1.\n",
    "\n",
    "    dangling: dict, optional\n",
    "      The outedges to be assigned to any \"dangling\" nodes, i.e., nodes without\n",
    "      any outedges. The dict key is the node the outedge points to and the dict\n",
    "      value is the weight of that outedge. By default, dangling nodes are given\n",
    "      outedges according to the personalization vector (uniform if not\n",
    "      specified) This must be selected to result in an irreducible transition\n",
    "      matrix (see notes under google_matrix). It may be common to have the\n",
    "      dangling dict to be the same as the personalization dict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pagerank : dictionary\n",
    "       Dictionary of nodes with PageRank as value\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> G = nx.DiGraph(nx.path_graph(4))\n",
    "    >>> pr = nx.pagerank_scipy(G, alpha=0.9)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The eigenvector calculation uses power iteration with a SciPy\n",
    "    sparse matrix representation.\n",
    "\n",
    "    This implementation works with Multi(Di)Graphs. For multigraphs the\n",
    "    weight between two nodes is set to be the sum of all edge weights\n",
    "    between those nodes.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    pagerank, pagerank_numpy, google_matrix\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Langville and C. Meyer,\n",
    "       \"A survey of eigenvector methods of web information retrieval.\"\n",
    "       http://citeseer.ist.psu.edu/713792.html\n",
    "    .. [2] Page, Lawrence; Brin, Sergey; Motwani, Rajeev and Winograd, Terry,\n",
    "       The PageRank citation ranking: Bringing order to the Web. 1999\n",
    "       http://dbpubs.stanford.edu:8090/pub/showDoc.Fulltext?lang=en&doc=1999-66&format=pdf\n",
    "    \"\"\"\n",
    "    import scipy.sparse\n",
    "\n",
    "    N = len(G)\n",
    "    if N == 0:\n",
    "        return {}\n",
    "\n",
    "    nodelist = G.nodes()\n",
    "    M = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, weight=weight,\n",
    "                                  dtype=float)\n",
    "    S = scipy.array(M.sum(axis=1)).flatten()\n",
    "    S[S != 0] = 1.0 / S[S != 0]\n",
    "    Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format='csr')\n",
    "    M = Q * M\n",
    "\n",
    "    # initial vector\n",
    "    x = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Personalization vector\n",
    "    if personalization is None:\n",
    "        p = scipy.repeat(1.0 / N, N)\n",
    "    else:\n",
    "        missing = set(nodelist) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError('Personalization vector dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        p = scipy.array([personalization[n] for n in nodelist],\n",
    "                        dtype=float)\n",
    "        p = p / p.sum()\n",
    "\n",
    "    # Dangling nodes\n",
    "    if dangling is None:\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        missing = set(nodelist) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError('Dangling node dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        # Convert the dangling dictionary into an array in nodelist order\n",
    "        dangling_weights = scipy.array([dangling[n] for n in nodelist],\n",
    "                                       dtype=float)\n",
    "        dangling_weights /= dangling_weights.sum()\n",
    "    is_dangling = scipy.where(S == 0)[0]\n",
    "\n",
    "    # power iteration: make up to max_iter iterations\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        x = alpha * (x * M + sum(x[is_dangling]) * dangling_weights) + \\\n",
    "            (1 - alpha) * p\n",
    "        # check convergence, l1 norm\n",
    "        err = scipy.absolute(x - xlast).sum()\n",
    "        if err < N * tol:\n",
    "            return dict(zip(nodelist, map(float, x)))\n",
    "    raise NetworkXError('pagerank_scipy: power iteration failed to converge '\n",
    "                        'in %d iterations.' % max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "G.add_edges_from([(1,2),(1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.48648582432442095, 2: 0.25675708783778944, 3: 0.25675708783778944}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank_scipy(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
